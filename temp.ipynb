{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from julia import Main, LightPropagation\n",
    "\n",
    "\"\"\"\n",
    "has properties to access absorption and scattering\n",
    "\n",
    "inherits from Layer for easy access to trainable_variables with further composition\n",
    "\"\"\"\n",
    "class Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, infinite=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.n = tf.constant(1.4, dtype=tf.float32)\n",
    "\n",
    "        if infinite:\n",
    "            self.infinite = True\n",
    "        else:\n",
    "            self.h = tf.Variable(10.0)\n",
    "    \n",
    "    def mu_a(self):\n",
    "        pass\n",
    "    \n",
    "    def mu_s(self):\n",
    "        pass\n",
    "\n",
    "class ConstLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self._mu_s = tf.Variable(0.1)\n",
    "        self._mu_a = tf.Variable(0.1)\n",
    "\n",
    "    def mu_s(self):\n",
    "        return self._mu_s\n",
    "\n",
    "    def mu_a(self):\n",
    "        return self._mu_a\n",
    "\n",
    "class VariableLayer(Layer):\n",
    "    def __init__(self, wavelengths, coeffs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.wavelengths = tf.constant(wavelengths, dtype=tf.float32)\n",
    "\n",
    "        # Scattering\n",
    "        self.a = tf.Variable(1.0)\n",
    "        self.b = tf.Variable(1.0)\n",
    "\n",
    "        # Absorption\n",
    "        self.coeffs = tf.constant(coeffs, dtype=tf.float32)\n",
    "        self.n_concs = self.coeffs.shape[1] # maybe the wrong one\n",
    "        self.concs = tf.Variable(tf.ones(self.n_concs), dtype=tf.float32)\n",
    "\n",
    "    def mu_s(self):\n",
    "        return self.a*(self.wavelengths / 500)**(-self.b)\n",
    "\n",
    "    def mu_a(self):\n",
    "        return tf.transpose(self.coeffs @ self.concs[:, None])[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([499.99997, 249.99998], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.1>)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = VariableLayer(np.array([1, 2]), np.array([[1, 2, 3], [1,2,3]])).mu_s()\n",
    "two = ConstLayer().mu_s()\n",
    "\n",
    "one, two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10. 10. 10.]\n",
      " [10. 10. 10.]], shape=(2, 3), dtype=float32) tf.Tensor(\n",
      "[[1.4 1.4 1.4]\n",
      " [1.4 1.4 1.4]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Material has a forward model which spits out the reflectance\n",
    "\"\"\"\n",
    "class Material(tf.keras.layers.Layer):\n",
    "    def __init__(self, layers, n_ext=1.4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = layers\n",
    "        self.n_ext = tf.constant(n_ext)\n",
    "    def reflectance(self, distance):\n",
    "        mu_as, mu_ss = self.build_coeffs()\n",
    "\n",
    "        size = mu_as.shape[0]\n",
    "\n",
    "        hs = [l.h for l in self.layers]\n",
    "        hs = self._build_constant_scalar_part(size, hs)\n",
    "\n",
    "        ns = [l.n for l in self.layers]\n",
    "        ns = self._build_constant_scalar_part(size, ns)\n",
    "\n",
    "        \n",
    "\n",
    "        print(hs, ns)\n",
    "\n",
    "    def build_coeffs(self):\n",
    "        mu_as = [l.mu_a() for l in self.layers]\n",
    "        mu_ss = [l.mu_s() for l in self.layers]\n",
    "\n",
    "        max_size = tf.reduce_max([tf.size(e) for e in mu_as])\n",
    "\n",
    "        mu_as = [tf.broadcast_to(e[..., None], (max_size, 1)) for e in mu_as]\n",
    "        mu_ss = [tf.broadcast_to(e[..., None], (max_size, 1)) for e in mu_ss]\n",
    "\n",
    "        mu_as = tf.concat(mu_as, -1)\n",
    "        mu_ss = tf.concat(mu_ss, -1)\n",
    "\n",
    "        return mu_as, mu_ss\n",
    "        \n",
    "    @staticmethod\n",
    "    def _build_constant_scalar_part(size, vals):\n",
    "        result = [tf.broadcast_to(e[..., None, None], (size, 1)) for e in vals]\n",
    "        result = tf.concat(result, -1)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def grad_reflectance():\n",
    "        pass\n",
    "\n",
    "    def call(self, i):\n",
    "        return self.reflectance(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mat = Material([ConstLayer(), ConstLayer(), VariableLayer(np.array([1, 2]), np.array([[1, 2, 3], [1,2,3]]))])\n",
    "\n",
    "mat(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.2, 10, 20, 1.4, 1.4, 10, 20, 0.0, 1.0]\n",
      "[0.2, 0.3, 30, 40, 1.4, 1.4, 30, 40, 0.0, 2.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-6.66386605e-002, -7.20620591e-018],\n",
       "        [-4.08142192e-005, -9.02531059e-114]]),\n",
       " array([[-1.66068124e-003,  7.41718173e-020],\n",
       "        [-3.45197390e-006,  6.81486915e-116]]),\n",
       " array([[ 4.17811075e-018, -4.17811075e-018],\n",
       "        [ 7.76220120e-114, -7.76220120e-114]]),\n",
       " array([[-2.22501153e-019,  1.06435096e-077],\n",
       "        [ 2.64771874e-114,  2.03060980e-321]]),\n",
       " array([[-0.00903799],\n",
       "        [-0.0028275 ]]),\n",
       " array([[-0.04690193],\n",
       "        [ 0.00212668]]))"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "accepts numpy arguments\n",
    "\n",
    "n layers\n",
    "mu_a    [bulk, n]\n",
    "mu_s    [bulk, n]\n",
    "n       [bulk, n]\n",
    "h       [bulk, n]\n",
    "z       [bulk, 1]\n",
    "rho     [bulk, 1]\n",
    "\"\"\"\n",
    "\n",
    "pack_call = lambda mu_a, mu_s, n, h, z, rho: mu_a + mu_s + n + h + [z] + [rho]\n",
    "unpack_result = lambda e, n: (e[..., :n], e[..., n:2*n], e[..., 2*n:3*n], e[..., 3*n:4*n], e[..., -2, None], e[..., -1, None])\n",
    "\n",
    "# julia indexing starts at 1\n",
    "julia_unpack_call = \"\"\"\n",
    "function unpack_call(x)\n",
    "    len = length(x)\n",
    "    n_layers = (len - 2) รท 4\n",
    "\n",
    "    mu_a = x[1:n_layers]\n",
    "    mu_s = x[n_layers+1:2*n_layers]\n",
    "    n = x[2*n_layers+1:3*n_layers]\n",
    "    h = x[3*n_layers+1:4*n_layers]\n",
    "    z = x[end-1]\n",
    "    rho = x[end]\n",
    "\n",
    "    LightPropagation.flux_DA_Nlay_cylinder_CW(\n",
    "        rho, mu_a, mu_s; n_ext=n_ext, n_med=n, l=h, a=a, z=z, MaxIter=MaxIter\n",
    "    )\n",
    "end\n",
    "\"\"\"\n",
    "\n",
    "Main.eval(julia_unpack_call)\n",
    "Main.eval(\"using LightPropagation; using ForwardDiff\")\n",
    "\n",
    "def reflectance(mu_as, mu_ss, ns, hs, zs, rhos, n_ext=1.4, a=100.0, MaxIter=10000):\n",
    "    result = np.zeros(rhos.shape)\n",
    "    for i in np.ndindex(mu_as.shape[:-1]):\n",
    "        z, rho = [e[i][0].item() for e in [zs, rhos]]\n",
    "        mu_a, mu_s, n, h = [e[i].tolist() for e in [mu_as, mu_ss, ns, hs]]\n",
    "        result[i][0] = LightPropagation.flux_DA_Nlay_cylinder_CW(\n",
    "            rho, mu_a, mu_s, n_ext=n_ext, n_med=n, l=h, a=a, z=z, MaxIter=MaxIter\n",
    "        )\n",
    "\n",
    "    return result\n",
    "\n",
    "def reflectance_gradient(mu_as, mu_ss, ns, hs, zs, rhos, n_ext=1.4, a=100.0, MaxIter=10000):\n",
    "    Main.n_ext = n_ext\n",
    "    Main.a = a\n",
    "    Main.MaxIter = MaxIter\n",
    "\n",
    "    n_layers = mu_as.shape[-1]\n",
    "    grad_dim = n_layers*4 + 2\n",
    "    grad_shape = np.array(rhos.shape)\n",
    "    grad_shape[-1] = grad_dim\n",
    "\n",
    "    gradient_result = np.zeros(grad_shape)\n",
    "    for i in np.ndindex(mu_as.shape[:-1]):\n",
    "        z, rho = [e[i][0].item() for e in [zs, rhos]]\n",
    "        mu_a, mu_s, n, h = [e[i].tolist() for e in [mu_as, mu_ss, ns, hs]]\n",
    "\n",
    "        combined = pack_call(mu_a, mu_s, n, h, z, rho)\n",
    "        print(combined)\n",
    "        Main.combined = combined\n",
    "\n",
    "        Main.eval(\"result = ForwardDiff.gradient(unpack_call, combined)\")\n",
    "        gradient_result[i] = Main.result\n",
    "    \n",
    "    return unpack_result(gradient_result, n_layers)\n",
    "\n",
    "mu_a = np.array([[0.1, 0.2], [0.2, 0.3]])\n",
    "mu_s = np.array([[10, 20], [30, 40]])\n",
    "h = np.array([[10, 20], [30, 40]])\n",
    "n = np.array([[1.4, 1.4], [1.4, 1.4]])\n",
    "z = np.array([[0.0], [0.0]])\n",
    "rho = np.array([[1.0], [2.0]])\n",
    "\n",
    "reflectance(mu_a, mu_s, n, h, z, rho)\n",
    "reflectance_gradient(mu_a, mu_s, n, h, z, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def tf_reflectance(mu_as, mu_ss, ns, hs, zs, rhos, n_ext=1.4, a=100.0, MaxIter=10000):\n",
    "    kwargs = dict(n_ext=1.4, a=100.0, MaxIter=10000)\n",
    "    wrap_ref = lambda *args: reflectance(*args, **kwargs)\n",
    "    wrap_grad_ref = lambda *args: reflectance_gradient(*args, **kwargs)\n",
    "\n",
    "    args = [mu_as, mu_ss, ns, hs, zs, rhos]\n",
    "    result = tf.numpy_function(wrap_ref, args, Tout=tf.float32)\n",
    "\n",
    "    def gradient(dy):\n",
    "        result = tf.numpy_function(wrap_grad_ref, args, Tout=tf.float32)\n",
    "        print(len(result))\n",
    "        print(result)\n",
    "        return [e*dy for e in result]\n",
    "\n",
    "    return result, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10000000149011612, 0.20000000298023224, 10, 20, 1.399999976158142, 1.399999976158142, 10, 20, 0.0, 1.0]\n",
      "[0.20000000298023224, 0.30000001192092896, 30, 40, 1.399999976158142, 1.399999976158142, 30, 40, 0.0, 2.0]\n",
      "6\n",
      "[<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
      "array([[-3.69918203e-002, -4.97115660e-018],\n",
      "       [-2.14565423e-005, -5.92068604e-114]])>, <tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
      "array([[-1.01748331e-003,  5.11769996e-020],\n",
      "       [-2.57609833e-005,  4.47063619e-116]])>, <tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
      "array([[-1.78808937e-002, -2.88253052e-018],\n",
      "       [-4.22836912e-003, -5.09208632e-114]])>, <tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
      "array([[-1.54564335e-019,  9.60060962e-078],\n",
      "       [ 1.73690227e-114,  1.68476385e-321]])>, <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
      "array([[0.00092179],\n",
      "       [0.02415864]])>, <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
      "array([[-0.02727397],\n",
      "       [ 0.03075881]])>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       " array([[-3.69918203e-002, -4.97115660e-018],\n",
       "        [-2.14565423e-005, -5.92068604e-114]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       " array([[-1.01748331e-003,  5.11769996e-020],\n",
       "        [-2.57609833e-005,  4.47063619e-116]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       " array([[-1.78808937e-002, -2.88253052e-018],\n",
       "        [-4.22836912e-003, -5.09208632e-114]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       " array([[-1.54564335e-019,  9.60060962e-078],\n",
       "        [ 1.73690227e-114,  0.00000000e+000]])>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       " array([[0.00092179],\n",
       "        [0.02415864]])>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       " array([[-0.02727397],\n",
       "        [ 0.03075881]])>]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_a = tf.Variable([[0.1, 0.2], [0.2, 0.3]])\n",
    "mu_s = tf.Variable([[10, 20], [30, 40]])\n",
    "h = tf.Variable([[10, 20], [30, 40]])\n",
    "n = tf.Variable([[1.4, 1.4], [1.4, 1.4]])\n",
    "z = tf.Variable([[0.0], [0.0]])\n",
    "rho = tf.Variable([[1.0], [2.0]])\n",
    "\n",
    "tf_reflectance(mu_a, mu_s, n, h, z, rho)\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    reflectance = tf_reflectance(mu_a, mu_s, n, h, z, rho)\n",
    "\n",
    "t.gradient(reflectance, [mu_a, mu_s, n, h, z, rho])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
